import argparse
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, accuracy_score, f1_score

RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)

def build_training_pairs(df: pd.DataFrame, negative_ratio: float = 1.0) -> pd.DataFrame:
    """
    Build a labeled dataset of (CDR3b_extended, Peptide) pairs.
    Positives are from the original vdjdb_positives.csv (label=1).
    Negatives are generated by mismatching CDR3b with random peptides (label=0).
    """
    pos = df[['CDR3b_extended', 'Peptide']].copy()
    pos = pos.rename(columns={'CDR3b_extended': 'cdr3b', 'Peptide': 'peptide'})
    pos['label'] = 1

    n_pos = len(pos)
    n_neg = int(negative_ratio * n_pos)

    # Create negatives by pairing each CDR3b with a random peptide from a different row
    cdr3b_list = pos['cdr3b'].values
    pep_list = pos['peptide'].values

    neg_cdr3b = []
    neg_pep = []
    for i in range(n_neg):
        # pick a base index and a mismatched peptide index
        idx_cdr3 = np.random.randint(0, n_pos)
        idx_pep = np.random.randint(0, n_pos)
        # ensure they are not the same positive pair
        while idx_pep == idx_cdr3:
            idx_pep = np.random.randint(0, n_pos)
        neg_cdr3b.append(cdr3b_list[idx_cdr3])
        neg_pep.append(pep_list[idx_pep])

    neg = pd.DataFrame({
        'cdr3b': neg_cdr3b,
        'peptide': neg_pep,
        'label': 0
    })

    all_pairs = pd.concat([pos, neg], ignore_index=True)
    all_pairs = all_pairs.sample(frac=1.0, random_state=RANDOM_SEED).reset_index(drop=True)
    return all_pairs

def make_text_representation(cdr3b: str, peptide: str) -> str:
    """
    Turn (cdr3b, peptide) into a simple text string for char-level TF-IDF.
    We keep them separated by a special token for clarity.
    """
    return f"CDR3:{cdr3b} PEP:{peptide}"

def prepare_features(df_pairs: pd.DataFrame):
    texts = [make_text_representation(c, p) for c, p in zip(df_pairs['cdr3b'], df_pairs['peptide'])]
    labels = df_pairs['label'].values
    return texts, labels

def train_baseline_model(train_csv: str, neg_ratio: float = 1.0, test_size: float = 0.2):
    # Load positives
    df = pd.read_csv(train_csv)
    # Build positive + negative pairs
    pairs = build_training_pairs(df, negative_ratio=neg_ratio)

    texts, labels = prepare_features(pairs)

    X_train, X_val, y_train, y_val = train_test_split(
        texts,
        labels,
        test_size=test_size,
        random_state=RANDOM_SEED,
        stratify=labels
    )

    # Char-level TF-IDF features
    vectorizer = TfidfVectorizer(
        analyzer='char',
        ngram_range=(1, 3),
        min_df=2
    )
    X_train_vec = vectorizer.fit_transform(X_train)
    X_val_vec = vectorizer.transform(X_val)

    # Logistic regression classifier
    clf = LogisticRegression(
        max_iter=500,
        n_jobs=-1,
        verbose=0
    )
    clf.fit(X_train_vec, y_train)

    # Validation performance
    val_probs = clf.predict_proba(X_val_vec)[:, 1]
    val_preds = (val_probs >= 0.5).astype(int)

    try:
        auc = roc_auc_score(y_val, val_probs)
    except Exception:
        auc = float("nan")

    acc = accuracy_score(y_val, val_preds)
    f1 = f1_score(y_val, val_preds)

    print("=== Validation Performance (Sequence-only baseline) ===")
    print(f"AUROC   : {auc:.4f}")
    print(f"Accuracy: {acc:.4f}")
    print(f"F1-score: {f1:.4f}")

    return vectorizer, clf

def predict_on_test(test_csv: str, vectorizer, clf, output_csv: str):
    test_df = pd.read_csv(test_csv)
    # Use CDR3b_extended and Peptide from test
    if "CDR3b_extended" not in test_df.columns or "Peptide" not in test_df.columns:
        raise ValueError("test.csv must have CDR3b_extended and Peptide columns.")

    texts = [
        make_text_representation(c, p)
        for c, p in zip(test_df["CDR3b_extended"], test_df["Peptide"])
    ]
    X_test_vec = vectorizer.transform(texts)
    probs = clf.predict_proba(X_test_vec)[:, 1]

    # If there's an ID column, keep it; otherwise create one
    if "ID" in test_df.columns:
        out = pd.DataFrame({"ID": test_df["ID"], "prob": probs})
    else:
        out = pd.DataFrame({"ID": np.arange(len(test_df)), "prob": probs})

    out.to_csv(output_csv, index=False)
    print(f"Saved predictions to {output_csv}")

def main():
    parser = argparse.ArgumentParser(description="Sequence-only baseline for TCR-epitope binding.")
    parser.add_argument("--train_csv", type=str, default="vdjdb_positives.csv",
                        help="Path to vdjdb_positives.csv (positives only).")
    parser.add_argument("--test_csv", type=str, default="test.csv",
                        help="Path to test.csv for prediction.")
    parser.add_argument("--neg_ratio", type=float, default=1.0,
                        help="Number of negative examples per positive (default: 1.0).")
    parser.add_argument("--test_size", type=float, default=0.2,
                        help="Fraction of data used as validation.")
    parser.add_argument("--output_csv", type=str, default="test_predictions_baseline.csv",
                        help="Where to save test predictions.")
    args = parser.parse_args()

    vectorizer, clf = train_baseline_model(
        train_csv=args.train_csv,
        neg_ratio=args.neg_ratio,
        test_size=args.test_size
    )

    predict_on_test(
        test_csv=args.test_csv,
        vectorizer=vectorizer,
        clf=clf,
        output_csv=args.output_csv
    )

if __name__ == "__main__":
    main()
